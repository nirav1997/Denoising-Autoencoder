{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"xulx3W4F_mph","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"74164957-fc80-4cb1-edb2-d9a2a8698e44","executionInfo":{"status":"ok","timestamp":1539244981999,"user_tz":-330,"elapsed":38156,"user":{"displayName":"NIRAV SHAH","photoUrl":"","userId":"15790282268235164347"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"metadata":{"id":"F3Fg9g84AGDN","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install keras"],"execution_count":0,"outputs":[]},{"metadata":{"id":"S25YhwZAAKUZ","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install h5py"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OhyX-tWiB0MK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1975},"outputId":"f4aad07f-f547-4c60-a496-e2d1daf78ecf","executionInfo":{"status":"ok","timestamp":1539245125018,"user_tz":-330,"elapsed":140577,"user":{"displayName":"NIRAV SHAH","photoUrl":"","userId":"15790282268235164347"}}},"cell_type":"code","source":["!python \"/content/drive/My Drive/COLAB/IP/model2.py\""],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","v2\n","Train on 48000 samples, validate on 12000 samples\n","Epoch 1/50\n","2018-10-11 08:03:21.205230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2018-10-11 08:03:21.205832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","totalMemory: 11.17GiB freeMemory: 11.10GiB\n","2018-10-11 08:03:21.205876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n","2018-10-11 08:03:21.502725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2018-10-11 08:03:21.502785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n","2018-10-11 08:03:21.502824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n","2018-10-11 08:03:21.503118: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2018-10-11 08:03:21.503197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","48000/48000 [==============================] - 6s 130us/step - loss: 0.1364 - val_loss: 0.0979\n","Epoch 2/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0831 - val_loss: 0.0729\n","Epoch 3/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0651 - val_loss: 0.0631\n","Epoch 4/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0558 - val_loss: 0.0513\n","Epoch 5/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0502 - val_loss: 0.0487\n","Epoch 6/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0461 - val_loss: 0.0453\n","Epoch 7/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0428 - val_loss: 0.0411\n","Epoch 8/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0404 - val_loss: 0.0394\n","Epoch 9/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0384 - val_loss: 0.0377\n","Epoch 10/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0369 - val_loss: 0.0354\n","Epoch 11/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0357 - val_loss: 0.0351\n","Epoch 12/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0346 - val_loss: 0.0337\n","Epoch 13/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0336 - val_loss: 0.0330\n","Epoch 14/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0328 - val_loss: 0.0317\n","Epoch 15/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0321 - val_loss: 0.0308\n","Epoch 16/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0314 - val_loss: 0.0312\n","Epoch 17/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0309 - val_loss: 0.0309\n","Epoch 18/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0303 - val_loss: 0.0296\n","Epoch 19/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0299 - val_loss: 0.0287\n","Epoch 20/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0294 - val_loss: 0.0283\n","Epoch 21/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0290 - val_loss: 0.0282\n","Epoch 22/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0286 - val_loss: 0.0282\n","Epoch 23/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0283 - val_loss: 0.0277\n","Epoch 24/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0279 - val_loss: 0.0274\n","Epoch 25/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0277 - val_loss: 0.0271\n","Epoch 26/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0273 - val_loss: 0.0266\n","Epoch 27/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0271 - val_loss: 0.0269\n","Epoch 28/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0268 - val_loss: 0.0268\n","Epoch 29/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0266 - val_loss: 0.0263\n","Epoch 30/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0263 - val_loss: 0.0262\n","Epoch 31/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0262 - val_loss: 0.0259\n","Epoch 32/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0259 - val_loss: 0.0251\n","Epoch 33/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0258 - val_loss: 0.0257\n","Epoch 34/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0256 - val_loss: 0.0253\n","Epoch 35/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0254 - val_loss: 0.0251\n","Epoch 36/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0252 - val_loss: 0.0252\n","Epoch 37/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0251 - val_loss: 0.0251\n","Epoch 38/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0249 - val_loss: 0.0246\n","Epoch 39/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0248 - val_loss: 0.0250\n","Epoch 40/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0246 - val_loss: 0.0241\n","Epoch 41/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0245 - val_loss: 0.0238\n","Epoch 42/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0244 - val_loss: 0.0246\n","Epoch 43/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0243 - val_loss: 0.0242\n","Epoch 44/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0241 - val_loss: 0.0234\n","Epoch 45/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0240 - val_loss: 0.0238\n","Epoch 46/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0239 - val_loss: 0.0233\n","Epoch 47/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0238 - val_loss: 0.0234\n","Epoch 48/50\n","48000/48000 [==============================] - 2s 49us/step - loss: 0.0237 - val_loss: 0.0239\n","Epoch 49/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0236 - val_loss: 0.0231\n","Epoch 50/50\n","48000/48000 [==============================] - 2s 50us/step - loss: 0.0235 - val_loss: 0.0232\n"],"name":"stdout"}]}]}